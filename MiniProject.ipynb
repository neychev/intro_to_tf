{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt\">Мини-проект  </span>\n",
    "\n",
    "<span style=\"color: red; font-size: 14pt\">Общий дедлайн: 01.07.2018 23:59:59</span>\n",
    "\n",
    "<span style=\"font-size: 12pt\">МАДМО 2018</span>, \n",
    "<span style=\"color:blue; font-size: 12pt\">BigDataTeam </span>\n",
    "<span style=\"color:blue; font-size: 12pt; font-family: 'Verdana'\"> info@bigdatateam.org </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Organization Info</h1> \n",
    "**Структура ДЗ**: \n",
    "- ДЗ состоит из двух частей\n",
    "    - первая часть: презентация бизнес-кейса о том, где можно применить методы машинного обучения в Сбербанке\n",
    "    - вторая честь: решение задачи классификации CIFAR с помощью CNN\n",
    "    - <span style=\"color: red;\">результаты первой части докладываются на семинаре в пятницу 29.06.2018 16:00</span>\n",
    "    - для предоставления обратной связи по бизнес-кейсу, драфт презентации с бизнес-кейсом следует прислать <span style=\"color: red;\">до 18:00 28.06.2018</span>\n",
    "    - <span style=\"color: red;\">результаты второй части проекта должны быть высланы до 01.07.2018 23:59</span>\n",
    "    \n",
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание (и первую и вторую часть) на почту ml_instructor@bigdatateam.org\n",
    "- Укажите тему письма в следующем формате MADMO2018_<номер_группы> <фамилия>, к примеру -- MADMO2018_1_ivanov\n",
    "- Первую часть сохраниете в файл <фамилия>_<группа>_miniproject_part1<номер задания>.ipnb, например: Ivanov_1_miniproject_part1.ipynb\n",
    "- Вторую часть сохраните в файл <фамилия>_<группа>_miniproject_part2.ipynb, наприрмер: Ivanov_1_miniproject_part2.ipynb\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте в Slack https://ml4sberbank1group.slack.com/messages/CB9KTG32N/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Часть 1: Применение изученных методов к задачам в Сбербанке </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание** \n",
    "\n",
    "Представьте, вам выпадает возможность улучшить жизнь в вашей организации (например, принести экономический эффект, упростить бизнес-процесс, автоматизировать ручной труд и т.п.) путём применения изученных в курсе методов. \n",
    "\n",
    "Требуется \n",
    "- найти задачу, которая требует решения (в вашем подразделении или в другом, или в целом для компании),\n",
    "- оценить бизнес-эффект от её решения,\n",
    "- описать математическую постановку задачи в терминах ML,\n",
    "    - это задача регрессии или классификации, \n",
    "    - что является целевой переменной,\n",
    "- описать данные, которые потребуются для формирования обучающей выборки (признаковое описание объектов и глубина обучающей выборки),\n",
    "- предложить методы ML для решения поставленной задачи,\n",
    "    - если методов несколько, следует сравнить их с точки зрения результата (точность предсказаний, интепретируемость,\n",
    "    сложность реализации и требуемые инфраструктурные затраты),\n",
    "- привести идеи по развитию решения задачи.\n",
    "\n",
    "Таким образом, презентация должна включать 3-4 слайда, доклад на семинаре должен занимать не более 6-7 минут.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Часть 2: CIFAR Quest </h1>\n",
    "### Полезные ссылки для выполнения задания\n",
    "#### Colab link (seminar): https://colab.research.google.com/drive/18xjvLspViCwTUXTBNiz_xKxlUblQuGPU\n",
    "#### Colab link (hw): https://colab.research.google.com/drive/1FlYpA-JHCZ1UilPScC2zWhZNCkE3Sv78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Задача состоит в создании CNN, которая показывает максимальную __accuracy__ на датасете CIFAR.\n",
    "* В конце задания нужно заполить __мини-отчёт__ по результатам создания CNN. Рекомендуется прочитать для начала структуру отчёта и далее заполнять его по ходу выполнения задания.\n",
    " \n",
    "## Оценка за прохождение квеста\n",
    "* +4 балла за качественно заполненный отчёт;\n",
    "* +1 балл за достижение каждого следующего порогового значения __accuracy__ на __TEST__ датасете:\n",
    "    * 40% (5 total)\n",
    "    * 45% (6 total)\n",
    "    * 50% (7 total)\n",
    "    * 55% (8 total)\n",
    "    * 60% (9 total)\n",
    "    * 65% (10 total)\n",
    "\n",
    "Это задание заключительное, так что в нём можно заработать дополнительные баллы:\n",
    "* +2 балла за достижение каждого следующего порогового значения __accuracy__ на __TEST__ датасете:\n",
    "    * 70% (12 total)\n",
    "    * 75% (14 total)\n",
    "    * 80% (16 total)\n",
    "    * 85% (18 total)\n",
    "    * 90% (20 total)\n",
    "    \n",
    "\n",
    "## Ограничения\n",
    "* Нельзя использовать предобученные сети (pre-trained networks).\n",
    "* вы __можете__ использовать валидационную выборку для обучения сети, но __НЕЛЬЗЯ__ ничего делать с тестовой выборкой, кроме запуска процедуры оценки __accuracy__ (которую вам предстоит самостоятельно реализовать)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data. It may work slow.\n",
    "!mkdir cifar10\n",
    "!curl -o cifar-10-python.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz -C cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='iso-8859-1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8').transpose(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your convolutional NN with Tensorflow (example in seminar).\n",
    "# For example 3 convolutions and poolings and dense layer after that.\n",
    "\n",
    "def train_fn(X, y, sess):\n",
    "    '''\n",
    "    returns tuple (loss, accuracy) for model train phase\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def eval_fn(X, y, sess):\n",
    "    '''\n",
    "    returns tuple (loss, accuracy) for model evaluation phase\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def predict_fn(X, sess):\n",
    "    '''\n",
    "    returns y_pred for model predict phase\n",
    "    '''\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @TODO: add your code for train&validation metrics plots:\n",
    "#  - epoch loss (train&validation - 2 curves on same figure)\n",
    "#  - epoch accurary (train&validation - 2 curves on same figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10 \n",
    "batch_size = 64\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(X_train, y_train, batch_size):\n",
    "            inputs, targets = batch\n",
    "            train_loss_batch, train_acc_batch = train_fn(inputs, targets, sess)\n",
    "            train_loss += train_loss_batch\n",
    "            train_acc += train_acc_batch\n",
    "            train_batches += 1\n",
    "    \n",
    "        # And a full pass over the validation data:\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "            inputs, targets = batch\n",
    "            valid_loss_batch, valid_acc_batch = eval_fn(inputs, targets, sess)\n",
    "            valid_loss += valid_loss_batch\n",
    "            valid_acc += valid_acc_batch\n",
    "            valid_batches += 1\n",
    "    \n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  train loss:\\t\\t{:.6f}\".format(train_loss / train_batches))\n",
    "        print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "        print(\"  valid loss:\\t\\t{:.6f}\".format(valid_loss / valid_batches))\n",
    "        print(\"  valid accuracy:\\t\\t{:.2f} %\".format(valid_acc / valid_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    _, acc = eval_fn(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 92.5:\n",
    "    print(\"Achievement unlocked: mage 80 lvl\")\n",
    "else:\n",
    "    print(\"Feed more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Отчет о выполнении\n",
    "\n",
    "### Привет, моё имя `...Luke Cifarwalker...`, и вот моя история\n",
    "\n",
    "Давным давно в далёкой далёкой галактике, когда у меня было ещё больше часа до дедлайна, у меня была идея:\n",
    "\n",
    "##### Я хотел построить такую нейронную сеть\n",
    "...\n",
    "\n",
    "Как я мог быть таким наивным?!\n",
    "\n",
    "##### На очередной итерации:\n",
    "....\n",
    "\n",
    "##### Наконец, после попытки № __iterations__ (или чашечки [чая/кофе])\n",
    "* финальная архитектура нейронной сети оказалась такой:\n",
    "....\n",
    "\n",
    "* в том числе нюанcы метода обучения и магии:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
